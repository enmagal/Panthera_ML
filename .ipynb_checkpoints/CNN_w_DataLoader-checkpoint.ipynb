{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57e5117e-426e-4649-859e-4888f6e5718a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for reading and displaying images\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for creating validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for evaluating the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "199b0e70-520b-409d-a84e-b4f97c3e2f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PantheraDataset:\n",
    "    def __init__(self, csv_file, root_dir, dataType, transform=None):\n",
    "        dataset = pd.read_csv(csv_file)\n",
    "        dataset = dataset.loc[dataset['Type'] == dataType]\n",
    "\n",
    "        # Update files name in the correct format\n",
    "        dataset['Photo'] = dataset['Photo'].map(lambda id: '{:08}'.format(id))\n",
    "        dataset['Photo'] = dataset['Photo'].astype(str)\n",
    "\n",
    "        nbrImg = len(dataset)\n",
    "        \n",
    "        dataset = dataset.reset_index(drop=True) \n",
    "        print(dataset.head())\n",
    "        \n",
    "        self.data = dataset\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        image_path = self.root_dir + str(self.data.loc[idx, 'Photo']) + '.jpg'\n",
    "        image = imread(image_path, as_gray=True)\n",
    "    \n",
    "        label = self.data.loc[idx, 'Animal'].astype(np.int64)\n",
    "        sample={'image': image, 'label': label}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c733f591-f204-443f-9270-17dc667a75d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resize(object):\n",
    "    \"\"\"Resize the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (int): Desired output size.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        img = resize(image, (self.output_size, self.output_size))\n",
    "\n",
    "        return {'image': img, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b585e413-477f-4187-ab75-018291ee63ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(object):\n",
    "    \"\"\"Normalize the image.\n",
    "\n",
    "    Args:\n",
    "        output_size (int): Desired output size.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        img = image/255.0\n",
    "\n",
    "        return {'image': img, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3e8dfee-1a31-4347-b202-6b27c8560102",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Transform data into tensor.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self = self\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "        \n",
    "        image = image.reshape(1, len(image), len(image))\n",
    "        img = torch.from_numpy(image)\n",
    "        label = torch.from_numpy(np.array([label]))\n",
    "\n",
    "        return {'image': img, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b37f9cd0-fea3-4083-b4a7-3bff156596d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    # resize\n",
    "    Resize(224),\n",
    "    # normalize\n",
    "    Normalize(0, 1),\n",
    "    # to-tensor\n",
    "    ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2662fbd0-c8cf-4a55-bf03-8df8739d72d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Photo  Animal  Panthera  ImgSizeX  ImgSizeY   Type\n",
      "0  12310285    True     False      4624      3468  train\n",
      "1  11030235    True      True      4624      3468  train\n",
      "2  11030234    True      True      4624      3468  train\n",
      "3  11030233    True      True      4624      3468  train\n",
      "4  10220225    True     False      4624      3468  train\n",
      "      Photo  Animal  Panthera  ImgSizeX  ImgSizeY  Type\n",
      "0  10120179   False     False      4624      3468  test\n",
      "1  09170135    True     False      4624      3468  test\n",
      "2  08300603   False     False      4624      3468  test\n",
      "3  08290108    True     False      4624      3468  test\n",
      "4  08190078   False     False      4624      3468  test\n"
     ]
    }
   ],
   "source": [
    "dataset_train = PantheraDataset('./panthera_dataset/list_photo_prep.csv', './panthera_dataset/img/', 'train', transform)\n",
    "dataset_test = PantheraDataset('./panthera_dataset/list_photo_prep.csv', './panthera_dataset/img/', 'test', transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5aab094-bdbb-46b9-a5ee-7eb1c8baec68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "print(dataset_test[8]['image'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08d527ef-f3c7-42d9-9626-05b7a5ed357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset_train, batch_size=32, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(dataset_test, batch_size=32, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f025b998-a205-48d2-863c-e399e6053973",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(Module):   \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.cnn_layers = Sequential(\n",
    "            # Defining a 2D convolution layer\n",
    "            Conv2d(1, 4, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(4),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Defining another 2D convolution layer\n",
    "            Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(4),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.linear_layers = Sequential(\n",
    "            Linear(12544, 2)\n",
    "        )\n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd2d521e-ca5f-4242-b392-d64e2f55644a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (cnn_layers): Sequential(\n",
      "    (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (linear_layers): Sequential(\n",
      "    (0): Linear(in_features=12544, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# defining the model\n",
    "model = Net()\n",
    "# defining the optimizer\n",
    "optimizer = Adam(model.parameters(), lr=0.07)\n",
    "# defining the loss function\n",
    "criterion = CrossEntropyLoss()\n",
    "# checking if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e62a05d-a86f-4b8a-9af4-23f4e4bbdf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, train_dl, val_dl, epochs=100, device='cpu'):\n",
    "    print('train() called: model=%s, opt=%s(lr=%f), epochs=%d, device=%s\\n' % \\\n",
    "          (type(model).__name__, type(optimizer).__name__,\n",
    "           optimizer.param_groups[0]['lr'], epochs, device))\n",
    "    \n",
    "    history = {} # Collects per-epoch loss and acc like Keras' fit().\n",
    "    history['loss'] = []\n",
    "    history['val_loss'] = []\n",
    "    history['acc'] = []\n",
    "    history['val_acc'] = []\n",
    "    \n",
    "    start_time_sec = time.time()\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "\n",
    "        # --- TRAIN AND EVALUATE ON TRAINING SET -----------------------------\n",
    "        train_loss         = 0.0\n",
    "        num_train_correct  = 0\n",
    "        num_train_examples = 0\n",
    "\n",
    "        for batch in train_dl:\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x    = batch[0].to(device)\n",
    "            y    = batch[1].to(device)\n",
    "            yhat = model(x)\n",
    "            loss = loss_fn(yhat, y)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss         += loss.data.item() * x.size(0)\n",
    "            num_train_correct  += (torch.max(yhat, 1)[1] == y).sum().item()\n",
    "            num_train_examples += x.shape[0]\n",
    "\n",
    "        train_acc   = num_train_correct / num_train_examples\n",
    "        train_loss  = train_loss / len(train_dl.dataset)\n",
    "\n",
    "\n",
    "        # --- EVALUATE ON VALIDATION SET -------------------------------------\n",
    "        val_loss       = 0.0\n",
    "        num_val_correct  = 0\n",
    "        num_val_examples = 0\n",
    "\n",
    "        for batch in val_dl:\n",
    "\n",
    "            x    = batch[0].to(device)\n",
    "            y    = batch[1].to(device)\n",
    "            yhat = model(x)\n",
    "            loss = loss_fn(yhat, y)\n",
    "\n",
    "            val_loss         += loss.data.item() * x.size(0)\n",
    "            num_val_correct  += (torch.max(yhat, 1)[1] == y).sum().item()\n",
    "            num_val_examples += y.shape[0]\n",
    "\n",
    "        val_acc  = num_val_correct / num_val_examples\n",
    "        val_loss = val_loss / len(val_dl.dataset)\n",
    "\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "          print('Epoch %3d/%3d, train loss: %5.2f, train acc: %5.2f, val loss: %5.2f, val acc: %5.2f' % \\\n",
    "                (epoch, epochs, train_loss, train_acc, val_loss, val_acc))\n",
    "\n",
    "        history['loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "\n",
    "    # END OF TRAINING LOOP\n",
    "\n",
    "\n",
    "    end_time_sec       = time.time()\n",
    "    total_time_sec     = end_time_sec - start_time_sec\n",
    "    time_per_epoch_sec = total_time_sec / epochs\n",
    "    print()\n",
    "    print('Time total:     %5.2f sec' % (total_time_sec))\n",
    "    print('Time per epoch: %5.2f sec' % (time_per_epoch_sec))\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23e44743-18cc-466d-aabf-578f9073ab1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train() called: model=Net, opt=Adam(lr=0.070000), epochs=100, device=cpu\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ENZO~1.MAG\\AppData\\Local\\Temp/ipykernel_35948/2108583237.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# training the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m history = train(\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ENZO~1.MAG\\AppData\\Local\\Temp/ipykernel_35948/3521845947.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, loss_fn, train_dl, val_dl, epochs, device)\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mx\u001b[0m    \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[0my\u001b[0m    \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# defining the number of epochs\n",
    "n_epochs = 25\n",
    "\n",
    "# training the model\n",
    "history = train(\n",
    "    model = model,\n",
    "    optimizer = optimizer,\n",
    "    loss_fn = CrossEntropyLoss(),\n",
    "    train_dl = train_loader,\n",
    "    val_dl = test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601ddbe6-ef91-4f68-b229-1774e9ab0ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce1fae5-92c6-430c-b7f4-15883aa764f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
