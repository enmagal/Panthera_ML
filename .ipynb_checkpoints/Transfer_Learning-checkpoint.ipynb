{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cc79ca1-f7e0-4adc-a6ee-75f706bf25aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "# for evaluating the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, models\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd2e8a41-2172-470f-b0d6-f9c931cc0ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PantheraDataset:\n",
    "    def __init__(self, csv_file, root_dir, dataType, transform=None):\n",
    "        dataset = pd.read_csv(csv_file)\n",
    "        dataset = dataset.loc[dataset['Type'] == dataType]\n",
    "\n",
    "        # Update files name in the correct format\n",
    "        dataset['Photo'] = dataset['Photo'].map(lambda id: '{:08}'.format(id))\n",
    "        dataset['Photo'] = dataset['Photo'].astype(str)\n",
    "\n",
    "        nbrImg = len(dataset)\n",
    "        \n",
    "        dataset = dataset.reset_index(drop=True) \n",
    "        \n",
    "        self.data = dataset\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        image_path = self.root_dir + str(self.data.loc[idx, 'Photo']) + '.jpg'\n",
    "        image = imread(image_path)\n",
    "    \n",
    "        label = self.data.loc[idx, 'Animal'].astype(np.int64)\n",
    "        sample={'image': image, 'label': label}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c974955-16ed-4a1b-868a-826d6911edb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resize(object):\n",
    "    \"\"\"Resize the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (int): Desired output size.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        img = resize(image, (self.output_size, self.output_size))\n",
    "\n",
    "        return {'image': img, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8717722-4d6f-4bee-81d6-cc214e52e347",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(object):\n",
    "    \"\"\"Normalize the image.\n",
    "\n",
    "    Args:\n",
    "        output_size (int): Desired output size.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        img = image/255.0\n",
    "\n",
    "        return {'image': img, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8220e552-be4f-415c-b283-62ed26d83304",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Transform data into tensor.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self = self\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "        \n",
    "        image = image.reshape(3, len(image), len(image))\n",
    "        img = torch.from_numpy(image).float()\n",
    "        label = torch.from_numpy(np.array(label))\n",
    "\n",
    "        return {'image': img, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98a2dffa-d333-48fb-a5d7-cfd1c8e9be3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    # resize\n",
    "    Resize(224),\n",
    "    # normalize\n",
    "    Normalize(0, 1),\n",
    "    # to-tensor\n",
    "    ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abd111c4-3637-4bc3-aa17-cb670816552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = PantheraDataset('./panthera_dataset/list_photo_prep.csv', './panthera_dataset/img/', 'train', transform)\n",
    "dataset_test = PantheraDataset('./panthera_dataset/list_photo_prep.csv', './panthera_dataset/img/', 'test', transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "816d44d5-662f-48bf-a674-d53e63acd0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "print(dataset_test[8]['label'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6c42980-1653-4a07-924e-528a09300511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': tensor([[[0.0024, 0.0022, 0.0023,  ..., 0.0023, 0.0023, 0.0020],\n",
       "          [0.0024, 0.0027, 0.0023,  ..., 0.0021, 0.0024, 0.0026],\n",
       "          [0.0022, 0.0024, 0.0026,  ..., 0.0038, 0.0035, 0.0038],\n",
       "          ...,\n",
       "          [0.0023, 0.0025, 0.0027,  ..., 0.0039, 0.0038, 0.0039],\n",
       "          [0.0022, 0.0022, 0.0024,  ..., 0.0026, 0.0026, 0.0023],\n",
       "          [0.0025, 0.0025, 0.0022,  ..., 0.0029, 0.0030, 0.0025]],\n",
       " \n",
       "         [[0.0022, 0.0024, 0.0022,  ..., 0.0037, 0.0035, 0.0036],\n",
       "          [0.0025, 0.0025, 0.0026,  ..., 0.0026, 0.0026, 0.0023],\n",
       "          [0.0026, 0.0024, 0.0022,  ..., 0.0029, 0.0030, 0.0025],\n",
       "          ...,\n",
       "          [0.0019, 0.0019, 0.0017,  ..., 0.0036, 0.0039, 0.0039],\n",
       "          [0.0036, 0.0039, 0.0038,  ..., 0.0039, 0.0039, 0.0039],\n",
       "          [0.0018, 0.0017, 0.0018,  ..., 0.0017, 0.0017, 0.0015]],\n",
       " \n",
       "         [[0.0018, 0.0019, 0.0017,  ..., 0.0036, 0.0039, 0.0038],\n",
       "          [0.0035, 0.0039, 0.0037,  ..., 0.0039, 0.0038, 0.0039],\n",
       "          [0.0018, 0.0017, 0.0019,  ..., 0.0016, 0.0019, 0.0016],\n",
       "          ...,\n",
       "          [0.0034, 0.0025, 0.0023,  ..., 0.0039, 0.0039, 0.0039],\n",
       "          [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
       "          [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039]]]),\n",
       " 'label': tensor(0)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6d79194-570e-4cb5-b0e0-25c0c195a658",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset_train, batch_size=4, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(dataset_test, batch_size=64, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e25af92-54ae-4923-bdac-6dfbe99f0c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet18 = models.resnet18(pretrained = True)\n",
    "\n",
    "# We freeze the parameters of the ResNet Model\n",
    "for param in ResNet18.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32b83261-bb5b-44d2-ade9-f65b1058bdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = ResNet18.fc.in_features\n",
    "ResNet18.fc = nn.Linear(num_ftrs, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f004ca9-021e-4f75-b64f-8eb7397dc18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet18 = ResNet18.to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized as\n",
    "# opposed to before.\n",
    "optimizer_conv = optim.SGD(ResNet18.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "636ebc96-dc71-4160-9e8b-733330a915f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, train_dl, val_dl, epochs=100, device='cpu'):\n",
    "    print('train() called: model=%s, opt=%s(lr=%f), epochs=%d, device=%s\\n' % \\\n",
    "          (type(model).__name__, type(optimizer).__name__,\n",
    "           optimizer.param_groups[0]['lr'], epochs, device))\n",
    "    \n",
    "    history = {} # Collects per-epoch loss and acc like Keras' fit().\n",
    "    history['loss'] = []\n",
    "    history['val_loss'] = []\n",
    "    history['acc'] = []\n",
    "    history['val_acc'] = []\n",
    "    \n",
    "    start_time_sec = time.time()\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "\n",
    "        # --- TRAIN AND EVALUATE ON TRAINING SET -----------------------------\n",
    "        train_loss         = 0.0\n",
    "        num_train_correct  = 0\n",
    "        num_train_examples = 0\n",
    "\n",
    "        batch_count = 0\n",
    "        \n",
    "        for batch in train_dl:\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x    = batch['image'].to(device)\n",
    "            y    = batch['label'].to(device)\n",
    "            yhat = model(x)\n",
    "            loss = loss_fn(yhat, y)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss         += loss.data.item() * x.size(0)\n",
    "            num_train_correct  += (torch.max(yhat, 1)[1] == y).sum().item()\n",
    "            num_train_examples += x.shape[0]\n",
    "            \n",
    "            print('batch n°', batch_count, ' done !')\n",
    "            batch_count += 1\n",
    "\n",
    "        train_acc   = num_train_correct / num_train_examples\n",
    "        train_loss  = train_loss / len(train_dl.dataset)\n",
    "\n",
    "\n",
    "        # --- EVALUATE ON VALIDATION SET -------------------------------------\n",
    "        val_loss       = 0.0\n",
    "        num_val_correct  = 0\n",
    "        num_val_examples = 0\n",
    "        \n",
    "        batch_count = 0\n",
    "\n",
    "        for batch in val_dl:\n",
    "\n",
    "            x    = batch['image'].to(device)\n",
    "            y    = batch['label'].to(device)\n",
    "            yhat = model(x)\n",
    "            loss = loss_fn(yhat, y)\n",
    "\n",
    "            val_loss         += loss.data.item() * x.size(0)\n",
    "            num_val_correct  += (torch.max(yhat, 1)[1] == y).sum().item()\n",
    "            num_val_examples += y.shape[0]\n",
    "            \n",
    "            print('batch n°', batch_count, ' done !')\n",
    "            batch_count += 1\n",
    "\n",
    "        val_acc  = num_val_correct / num_val_examples\n",
    "        val_loss = val_loss / len(val_dl.dataset)\n",
    "\n",
    "\n",
    "        print('Epoch %3d/%3d, train loss: %5.2f, train acc: %5.2f, val loss: %5.2f, val acc: %5.2f' % (epoch, epochs, train_loss, train_acc, val_loss, val_acc))\n",
    "\n",
    "        history['loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "\n",
    "    # END OF TRAINING LOOP\n",
    "\n",
    "\n",
    "    end_time_sec       = time.time()\n",
    "    total_time_sec     = end_time_sec - start_time_sec\n",
    "    time_per_epoch_sec = total_time_sec / epochs\n",
    "    print()\n",
    "    print('Time total:     %5.2f sec' % (total_time_sec))\n",
    "    print('Time per epoch: %5.2f sec' % (time_per_epoch_sec))\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6866da-e144-42cd-b35b-6b2625879df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train() called: model=ResNet, opt=SGD(lr=0.001000), epochs=5, device=cpu\n",
      "\n",
      "batch n° 0  done !\n",
      "batch n° 1  done !\n",
      "batch n° 2  done !\n",
      "batch n° 3  done !\n",
      "batch n° 4  done !\n",
      "batch n° 5  done !\n",
      "batch n° 6  done !\n",
      "batch n° 7  done !\n",
      "batch n° 8  done !\n",
      "batch n° 9  done !\n",
      "batch n° 10  done !\n",
      "batch n° 11  done !\n",
      "batch n° 12  done !\n",
      "batch n° 13  done !\n",
      "batch n° 14  done !\n",
      "batch n° 15  done !\n",
      "batch n° 16  done !\n",
      "batch n° 0  done !\n",
      "Epoch   1/  5, train loss:  0.57, train acc:  0.76, val loss:  0.30, val acc:  0.94\n",
      "batch n° 0  done !\n",
      "batch n° 1  done !\n",
      "batch n° 2  done !\n",
      "batch n° 3  done !\n"
     ]
    }
   ],
   "source": [
    "history = train(ResNet18, optimizer_conv, loss_fn, train_loader, test_loader, epochs=5, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb8d3dd-20f0-4340-96ea-e28faf52170e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
